{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okB-yoKFn7kQ"
      },
      "outputs": [],
      "source": [
        "!pip install nemo-toolkit[asr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "v8CP3O30Iw-t"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# 1. Fun√ß√µes auxiliares (ASR)\n",
        "# ------------------------------\n",
        "import librosa\n",
        "import numpy as np\n",
        "import time\n",
        "import nemo.collections.asr as nemo_asr\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import torch\n",
        "\n",
        "def carregar_audio(caminho, sr=16000):\n",
        "    \"\"\"Carrega arquivo de √°udio e converte para 16 kHz mono, retornando dura√ß√£o.\"\"\"\n",
        "    audio, _ = librosa.load(caminho, sr=sr, mono=True)\n",
        "    return np.array(audio, dtype=np.float32), sr, len(audio) / sr  # dura√ß√£o em segundos\n",
        "\n",
        "# ------------------------------\n",
        "# Fun√ß√£o para modelos NeMo\n",
        "# ------------------------------\n",
        "def avaliar_modelo_nemo(modelo_id, caminho_audio):\n",
        "    \"\"\"\n",
        "    Executa infer√™ncia com modelos NeMo, retornando:\n",
        "    - RTF\n",
        "    - lat√™ncia total (segundos)\n",
        "    - transcri√ß√£o\n",
        "    \"\"\"\n",
        "    print(f\"üîΩ Carregando modelo NeMo {modelo_id} ...\")\n",
        "    asr_model = nemo_asr.models.ASRModel.from_pretrained(modelo_id)\n",
        "\n",
        "    # Carregar √°udio e obter dura√ß√£o\n",
        "    audio, sr, duracao = carregar_audio(caminho_audio, sr=16000)\n",
        "\n",
        "    inicio = time.time()\n",
        "    transcricao_obj = asr_model.transcribe([caminho_audio])[0]\n",
        "    fim = time.time()\n",
        "\n",
        "    tempo_processamento = fim - inicio  # lat√™ncia total em segundos\n",
        "    rtf = tempo_processamento / duracao  # c√°lculo do RTF\n",
        "\n",
        "    transcricao_texto = getattr(transcricao_obj, \"text\", str(transcricao_obj))\n",
        "    return rtf, tempo_processamento, transcricao_texto\n",
        "\n",
        "# ------------------------------\n",
        "# Fun√ß√£o para modelos Hugging Face\n",
        "# ------------------------------\n",
        "def avaliar_modelo_hf(modelo_id, caminho_audio):\n",
        "    \"\"\"\n",
        "    Executa infer√™ncia com modelos Hugging Face, retornando:\n",
        "    - RTF\n",
        "    - lat√™ncia total (segundos)\n",
        "    - transcri√ß√£o\n",
        "    \"\"\"\n",
        "    print(f\"üîΩ Carregando modelo HF {modelo_id} ...\")\n",
        "    processor = Wav2Vec2Processor.from_pretrained(modelo_id)\n",
        "    model = Wav2Vec2ForCTC.from_pretrained(modelo_id)\n",
        "    model.eval()\n",
        "\n",
        "    audio, sr, duracao = carregar_audio(caminho_audio, sr=16000)\n",
        "    input_values = processor(audio, sampling_rate=sr, return_tensors=\"pt\").input_values\n",
        "\n",
        "    inicio = time.time()\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_values).logits\n",
        "    fim = time.time()\n",
        "\n",
        "    tempo_processamento = fim - inicio\n",
        "    rtf = tempo_processamento / duracao\n",
        "\n",
        "    pred_ids = torch.argmax(logits, dim=-1)\n",
        "    transcricao_texto = processor.batch_decode(pred_ids)[0]\n",
        "\n",
        "    return rtf, tempo_processamento, transcricao_texto\n",
        "\n",
        "# ------------------------------\n",
        "# Fun√ß√£o para calcular m√©tricas\n",
        "# ------------------------------\n",
        "def calcular_metricas(modelo, rtf, latencia_total, saida, referencia=None, rank=None):\n",
        "    \"\"\"\n",
        "    Retorna dicion√°rio com:\n",
        "    - Rank\n",
        "    - Modelo\n",
        "    - RTF\n",
        "    - Lat√™ncia total (s e ms)\n",
        "    - Transcri√ß√£o\n",
        "    - WER aproximado\n",
        "    \"\"\"\n",
        "    if not isinstance(saida, str) and hasattr(saida, 'text'):\n",
        "        saida = saida.text\n",
        "    elif not isinstance(saida, str):\n",
        "        saida = str(saida)\n",
        "\n",
        "    resultado = {\n",
        "        \"Rank\": rank if rank is not None else \"-\",\n",
        "        \"Modelo\": modelo,\n",
        "        \"RTF\": round(rtf, 3),\n",
        "        \"Lat√™ncia (s)\": round(latencia_total, 3),\n",
        "        \"Lat√™ncia (ms)\": round(latencia_total * 1000, 2),\n",
        "        \"Transcri√ß√£o\": saida,\n",
        "        \"WER aproximado\": None\n",
        "    }\n",
        "\n",
        "    if referencia:\n",
        "        ref_tokens = referencia.lower().split()\n",
        "        out_tokens = saida.lower().split()\n",
        "        intersecao = len(set(ref_tokens) & set(out_tokens))\n",
        "        wer_aprox = 1 - (intersecao / len(ref_tokens)) if ref_tokens else 1.0\n",
        "        resultado[\"WER aproximado\"] = round(wer_aprox, 3)\n",
        "\n",
        "    return resultado\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KW7Ra1I-I57n"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Avalia√ß√£o de modelos ASR espec√≠ficos (PT-BR) - com RTF + LAT√äNCIA\n",
        "# ------------------------------\n",
        "\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import nemo.collections.asr as nemo_asr\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# ------------------------------\n",
        "# Fun√ß√µes auxiliares\n",
        "# ------------------------------\n",
        "\n",
        "def carregar_audio(caminho, sr=16000):\n",
        "    \"\"\"Carrega arquivo de √°udio, converte para 16 kHz mono e retorna dura√ß√£o em segundos.\"\"\"\n",
        "    audio, _ = librosa.load(caminho, sr=sr, mono=True)\n",
        "    audio = np.array(audio, dtype=np.float32)\n",
        "    duracao = len(audio) / sr if sr > 0 else 0.0\n",
        "    return audio, sr, duracao\n",
        "\n",
        "def avaliar_modelo_nemo(modelo_id, caminho_audio):\n",
        "    \"\"\"Executa infer√™ncia com modelos NeMo e retorna RTF, lat√™ncia total e transcri√ß√£o.\"\"\"\n",
        "    print(f\"\\nüîπ Avaliando modelo NeMo: {modelo_id}\")\n",
        "    asr_model = nemo_asr.models.ASRModel.from_pretrained(modelo_id)\n",
        "\n",
        "    _, _, duracao = carregar_audio(caminho_audio, sr=16000)\n",
        "\n",
        "    inicio = time.time()\n",
        "    transcricao_obj = asr_model.transcribe([caminho_audio])[0]\n",
        "    fim = time.time()\n",
        "\n",
        "    tempo_processamento = fim - inicio\n",
        "    rtf = tempo_processamento / duracao if duracao > 0 else float(\"inf\")\n",
        "\n",
        "    transcricao_texto = getattr(transcricao_obj, \"text\", str(transcricao_obj))\n",
        "    return rtf, tempo_processamento, transcricao_texto\n",
        "\n",
        "def avaliar_modelo_hf(modelo_id, caminho_audio):\n",
        "    \"\"\"Executa infer√™ncia com modelos Hugging Face e retorna RTF, lat√™ncia total e transcri√ß√£o.\"\"\"\n",
        "    print(f\"\\nüîπ Avaliando modelo HF: {modelo_id}\")\n",
        "    processor = Wav2Vec2Processor.from_pretrained(modelo_id)\n",
        "    model = Wav2Vec2ForCTC.from_pretrained(modelo_id)\n",
        "    model.eval()\n",
        "\n",
        "    audio, sr, duracao = carregar_audio(caminho_audio)\n",
        "    if sr != 16000:\n",
        "        raise ValueError(\"O modelo HF requer √°udio em 16 kHz.\")\n",
        "\n",
        "    inputs = processor(audio, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "    inicio = time.time()\n",
        "    with torch.no_grad():\n",
        "        logits = model(inputs.input_values).logits\n",
        "    fim = time.time()\n",
        "\n",
        "    tempo_processamento = fim - inicio\n",
        "    rtf = tempo_processamento / duracao if duracao > 0 else float(\"inf\")\n",
        "\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcricao_texto = processor.batch_decode(predicted_ids)[0]\n",
        "\n",
        "    return rtf, tempo_processamento, transcricao_texto\n",
        "\n",
        "def calcular_metricas(modelo, rtf, latencia_total, saida, referencia=None):\n",
        "    \"\"\"Retorna m√©tricas b√°sicas para compara√ß√£o de transcri√ß√£o (inclui RTF + lat√™ncia total).\"\"\"\n",
        "    resultado = {\n",
        "        \"Modelo\": modelo,\n",
        "        \"RTF\": round(rtf, 3),\n",
        "        \"Lat√™ncia (s)\": round(latencia_total, 3),\n",
        "        \"Lat√™ncia (ms)\": round(latencia_total * 1000, 2),\n",
        "        \"Transcri√ß√£o\": saida\n",
        "    }\n",
        "\n",
        "    if referencia:\n",
        "        if not isinstance(saida, str):\n",
        "            saida = str(saida)\n",
        "\n",
        "        ref_tokens = referencia.lower().split()\n",
        "        out_tokens = saida.lower().split()\n",
        "\n",
        "        intersecao = len(set(ref_tokens) & set(out_tokens))\n",
        "        wer_aprox = 1 - (intersecao / len(ref_tokens)) if ref_tokens else 1.0\n",
        "\n",
        "        resultado[\"WER aproximado\"] = round(wer_aprox, 3)\n",
        "\n",
        "    return resultado\n",
        "\n",
        "def limpar_transcricao(x):\n",
        "    \"\"\"Extrai texto se for objeto Hypothesis do NeMo.\"\"\"\n",
        "    try:\n",
        "        if isinstance(x, (list, tuple)) and len(x) > 0:\n",
        "            return getattr(x[0], \"text\", str(x[0]))\n",
        "        return getattr(x, \"text\", str(x))\n",
        "    except Exception:\n",
        "        return str(x) if x is not None else \"\"\n",
        "\n",
        "# ------------------------------\n",
        "# Configura√ß√µes\n",
        "# ------------------------------\n",
        "\n",
        "audio_teste = \"/content/audio3.wav\"\n",
        "referencia_texto = \"um dois tr√™s testando isto √© um exemplo para a transcri√ß√£o de √°udio para texto\"\n",
        "\n",
        "if not os.path.isfile(audio_teste):\n",
        "    raise FileNotFoundError(f\"Arquivo de √°udio n√£o encontrado: {audio_teste}\")\n",
        "\n",
        "# ------------------------------\n",
        "# Lista de modelos para testar\n",
        "# ------------------------------\n",
        "modelos = [\n",
        "     {\"nome\": \"FastConformer-Hybrid\", \"id\": \"nvidia/stt_pt_fastconformer_hybrid_large_pc\", \"tipo\": \"nemo\"},\n",
        "     {\"nome\": \"Citrinet-PT-Gamma-0.25\", \"id\": \"neongeckocom/stt_pt_citrinet_512_gamma_0_25\", \"tipo\": \"nemo\"},\n",
        "     {\"nome\": \"QuartzNet-PT-Ottema\", \"id\": \"ottema/stt_pt_quartznet15x5_ctc_small\", \"tipo\": \"nemo\"},\n",
        "     {\"nome\": \"QuartzNet-PT\", \"id\": \"dominguesm/stt_pt_quartznet15x5_ctc_small\", \"tipo\": \"nemo\"},\n",
        "     {\"nome\": \"Parakeet-TDT-0.6b-v3\", \"id\": \"nvidia/parakeet-tdt-0.6b-v3\", \"tipo\": \"nemo\"},\n",
        "     {\"nome\": \"wav2vec2-PT-BR-Light\", \"id\": \"danielpedrozo/wav2vec2-portuguese-wpp-checkpoint-480\", \"tipo\": \"hf\"},\n",
        "]\n",
        "\n",
        "# ------------------------------\n",
        "# Execu√ß√£o e coleta de resultados\n",
        "# ------------------------------\n",
        "resultados = []\n",
        "\n",
        "for modelo in modelos:\n",
        "    try:\n",
        "        if modelo[\"tipo\"] == \"nemo\":\n",
        "            rtf, latencia_total, transcricao = avaliar_modelo_nemo(modelo[\"id\"], audio_teste)\n",
        "        elif modelo[\"tipo\"] == \"hf\":\n",
        "            rtf, latencia_total, transcricao = avaliar_modelo_hf(modelo[\"id\"], audio_teste)\n",
        "\n",
        "        metricas = calcular_metricas(modelo[\"nome\"], rtf, latencia_total, transcricao, referencia_texto)\n",
        "        resultados.append(metricas)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao avaliar modelo {modelo['nome']}: {e}\")\n",
        "\n",
        "# ------------------------------\n",
        "# Cria√ß√£o do DataFrame\n",
        "# ------------------------------\n",
        "df_resultados = pd.DataFrame(resultados)\n",
        "\n",
        "if \"Transcri√ß√£o\" in df_resultados.columns:\n",
        "    df_resultados[\"Transcri√ß√£o\"] = df_resultados[\"Transcri√ß√£o\"].apply(limpar_transcricao)\n",
        "\n",
        "# -------- ORDENA√á√ÉO --------\n",
        "colunas_ordem = [c for c in [\"WER aproximado\", \"RTF\"] if c in df_resultados.columns]\n",
        "\n",
        "if colunas_ordem:\n",
        "    df_resultados = df_resultados.sort_values(\n",
        "        by=colunas_ordem,\n",
        "        ascending=[True] * len(colunas_ordem),\n",
        "        ignore_index=True\n",
        "    )\n",
        "\n",
        "# Adicionar coluna de ranking\n",
        "df_resultados.insert(0, \"Rank\", range(1, len(df_resultados) + 1))\n",
        "\n",
        "# -------- VISUALIZA√á√ÉO --------\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "\n",
        "print(\"\\nüîπ Resultados ordenados (melhor WER e menor RTF):\")\n",
        "print(df_resultados[[\"Rank\", \"Modelo\", \"WER aproximado\", \"RTF\", \"Lat√™ncia (ms)\", \"Transcri√ß√£o\"]])\n",
        "\n",
        "# -------- EXPORTA√á√ÉO --------\n",
        "df_resultados.to_csv(\"resultados_asr.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "with open(\"resultados_asr.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for _, row in df_resultados.iterrows():\n",
        "        f.write(f\"Modelo: {row['Modelo']}\\n\")\n",
        "        f.write(f\"WER aproximado: {row.get('WER aproximado', 'N/A')}\\n\")\n",
        "        f.write(f\"RTF: {row['RTF']}\\n\")\n",
        "        f.write(f\"Lat√™ncia (ms): {row['Lat√™ncia (ms)']}\\n\")\n",
        "        f.write(f\"Transcri√ß√£o: {row['Transcri√ß√£o']}\\n\")\n",
        "        f.write(\"-\" * 60 + \"\\n\")\n",
        "\n",
        "print(\"\\n‚úÖ Resultados salvos em resultados_asr.csv e resultados_asr.txt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaMbcF8So6ON"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}