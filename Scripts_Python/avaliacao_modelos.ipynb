{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "okB-yoKFn7kQ"
      },
      "outputs": [],
      "source": [
        "!pip install nemo-toolkit[asr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "v8CP3O30Iw-t"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# 1. Fun√ß√µes auxiliares (ASR)\n",
        "# ------------------------------\n",
        "import librosa\n",
        "import numpy as np\n",
        "import time\n",
        "import nemo.collections.asr as nemo_asr\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import torch\n",
        "\n",
        "def carregar_audio(caminho, sr=16000):\n",
        "    \"\"\"Carrega arquivo de √°udio e converte para 16 kHz mono.\"\"\"\n",
        "    audio, _ = librosa.load(caminho, sr=sr, mono=True)\n",
        "    return np.array(audio, dtype=np.float32), sr\n",
        "\n",
        "# ------------------------------\n",
        "# Fun√ß√£o para modelos NeMo\n",
        "# ------------------------------\n",
        "def avaliar_modelo_nemo(modelo_id, caminho_audio):\n",
        "    \"\"\"\n",
        "    Executa infer√™ncia com modelos NeMo e retorna lat√™ncia e transcri√ß√£o.\n",
        "    \"\"\"\n",
        "    print(f\"üîΩ Carregando modelo NeMo {modelo_id} ...\")\n",
        "    asr_model = nemo_asr.models.ASRModel.from_pretrained(modelo_id)\n",
        "\n",
        "    inicio = time.time()\n",
        "    transcricao_obj = asr_model.transcribe([caminho_audio])[0]\n",
        "    fim = time.time()\n",
        "\n",
        "    latencia_ms = (fim - inicio) * 1000\n",
        "    transcricao_texto = getattr(transcricao_obj, \"text\", str(transcricao_obj))\n",
        "\n",
        "    return latencia_ms, transcricao_texto\n",
        "\n",
        "# ------------------------------\n",
        "# Fun√ß√£o para modelos Hugging Face\n",
        "# ------------------------------\n",
        "def avaliar_modelo_hf(modelo_id, caminho_audio):\n",
        "    \"\"\"\n",
        "    Executa infer√™ncia com modelos Hugging Face (Wav2Vec2/Whisper) e retorna lat√™ncia e transcri√ß√£o.\n",
        "    \"\"\"\n",
        "    print(f\"üîΩ Carregando modelo HF {modelo_id} ...\")\n",
        "    processor = Wav2Vec2Processor.from_pretrained(modelo_id)\n",
        "    model = Wav2Vec2ForCTC.from_pretrained(modelo_id)\n",
        "    model.eval()\n",
        "\n",
        "    audio, sr = carregar_audio(caminho_audio, sr=16000)\n",
        "    input_values = processor(audio, sampling_rate=sr, return_tensors=\"pt\").input_values\n",
        "\n",
        "    inicio = time.time()\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_values).logits\n",
        "    pred_ids = torch.argmax(logits, dim=-1)\n",
        "    transcricao_texto = processor.batch_decode(pred_ids)[0]\n",
        "    fim = time.time()\n",
        "\n",
        "    latencia_ms = (fim - inicio) * 1000\n",
        "    return latencia_ms, transcricao_texto\n",
        "\n",
        "# ------------------------------\n",
        "# Fun√ß√£o para calcular m√©tricas\n",
        "# ------------------------------\n",
        "def calcular_metricas(modelo, latencia, saida, referencia=None, rank=None):\n",
        "    \"\"\"\n",
        "    Retorna dicion√°rio com m√©tricas: Rank, Modelo, Lat√™ncia, Transcri√ß√£o e WER aproximado.\n",
        "    \"\"\"\n",
        "    # Garantir que a sa√≠da seja string\n",
        "    if not isinstance(saida, str) and hasattr(saida, 'text'):\n",
        "        saida = saida.text\n",
        "    elif not isinstance(saida, str):\n",
        "        saida = str(saida)\n",
        "\n",
        "    resultado = {\n",
        "        \"Rank\": rank if rank is not None else \"-\",\n",
        "        \"Modelo\": modelo,\n",
        "        \"Lat√™ncia (ms)\": round(latencia, 2),\n",
        "        \"Transcri√ß√£o\": saida,\n",
        "        \"WER aproximado\": None  # Sempre presente para evitar KeyError\n",
        "    }\n",
        "\n",
        "    if referencia:\n",
        "        ref_tokens = referencia.lower().split()\n",
        "        out_tokens = saida.lower().split()\n",
        "        intersecao = len(set(ref_tokens) & set(out_tokens))\n",
        "        wer_aprox = 1 - (intersecao / len(ref_tokens)) if ref_tokens else 1.0\n",
        "        resultado[\"WER aproximado\"] = round(wer_aprox, 3)\n",
        "\n",
        "    return resultado\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "KW7Ra1I-I57n"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ------------------------------\n",
        "# Avalia√ß√£o de modelos ASR espec√≠ficos (PT-BR)\n",
        "# ------------------------------\n",
        "\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import nemo.collections.asr as nemo_asr\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# ------------------------------\n",
        "# Fun√ß√µes auxiliares\n",
        "# ------------------------------\n",
        "\n",
        "def carregar_audio(caminho, sr=16000):\n",
        "    \"\"\"Carrega arquivo de √°udio e converte para 16 kHz mono.\"\"\"\n",
        "    audio, _ = librosa.load(caminho, sr=sr, mono=True)\n",
        "    return np.array(audio, dtype=np.float32), sr\n",
        "\n",
        "def avaliar_modelo_nemo(modelo_id, caminho_audio):\n",
        "    \"\"\"Executa infer√™ncia com modelos NeMo (QuartzNet, Citrinet, FastConformer, Parakeet).\"\"\"\n",
        "    print(f\"\\nüîπ Avaliando modelo NeMo: {modelo_id}\")\n",
        "    asr_model = nemo_asr.models.ASRModel.from_pretrained(modelo_id)\n",
        "\n",
        "    inicio = time.time()\n",
        "    transcricao_obj = asr_model.transcribe([caminho_audio])[0]\n",
        "    fim = time.time()\n",
        "\n",
        "    # Extrair texto se for objeto Hypothesis\n",
        "    transcricao_texto = getattr(transcricao_obj, \"text\", str(transcricao_obj))\n",
        "    latencia_ms = (fim - inicio) * 1000\n",
        "    return latencia_ms, transcricao_texto\n",
        "\n",
        "def avaliar_modelo_hf(modelo_id, caminho_audio):\n",
        "    \"\"\"Executa infer√™ncia com modelos Hugging Face (ex: wav2vec2).\"\"\"\n",
        "    print(f\"\\nüîπ Avaliando modelo HF: {modelo_id}\")\n",
        "    processor = Wav2Vec2Processor.from_pretrained(modelo_id)\n",
        "    model = Wav2Vec2ForCTC.from_pretrained(modelo_id)\n",
        "\n",
        "    audio, sr = carregar_audio(caminho_audio)\n",
        "    if sr != 16000:\n",
        "        raise ValueError(\"O modelo HF requer √°udio em 16 kHz.\")\n",
        "\n",
        "    inputs = processor(audio, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
        "    inicio = time.time()\n",
        "    with torch.no_grad():\n",
        "        logits = model(inputs.input_values).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    fim = time.time()\n",
        "\n",
        "    transcricao_texto = processor.batch_decode(predicted_ids)[0]\n",
        "    latencia_ms = (fim - inicio) * 1000\n",
        "    return latencia_ms, transcricao_texto\n",
        "\n",
        "def calcular_metricas(modelo, latencia, saida, referencia=None):\n",
        "    \"\"\"Retorna m√©tricas b√°sicas para compara√ß√£o de transcri√ß√£o.\"\"\"\n",
        "    resultado = {\n",
        "        \"Modelo\": modelo,\n",
        "        \"Lat√™ncia (ms)\": round(latencia, 2),\n",
        "        \"Transcri√ß√£o\": saida\n",
        "    }\n",
        "\n",
        "    if referencia:\n",
        "        if not isinstance(saida, str):\n",
        "            saida = str(saida)\n",
        "        ref_tokens = referencia.lower().split()\n",
        "        out_tokens = saida.lower().split()\n",
        "        intersecao = len(set(ref_tokens) & set(out_tokens))\n",
        "        wer_aprox = 1 - (intersecao / len(ref_tokens)) if ref_tokens else 1.0\n",
        "        resultado[\"WER aproximado\"] = round(wer_aprox, 3)\n",
        "\n",
        "    return resultado\n",
        "\n",
        "def limpar_transcricao(x):\n",
        "    \"\"\"Extrai texto se for objeto Hypothesis do NeMo.\"\"\"\n",
        "    try:\n",
        "        if isinstance(x, (list, tuple)) and len(x) > 0:\n",
        "            return getattr(x[0], \"text\", str(x[0]))\n",
        "        return getattr(x, \"text\", str(x))\n",
        "    except Exception:\n",
        "        return str(x) if x is not None else \"\"\n",
        "\n",
        "# ------------------------------\n",
        "# Configura√ß√µes\n",
        "# ------------------------------\n",
        "\n",
        "audio_teste = \"/content/audio3.wav\"          #/Caminho para o √°udio\n",
        "referencia_texto = \"este √© um exemplo de fala\"\n",
        "\n",
        "if not os.path.isfile(audio_teste):\n",
        "    raise FileNotFoundError(f\"Arquivo de √°udio n√£o encontrado: {audio_teste}\")\n",
        "\n",
        "# ------------------------------\n",
        "# Lista de modelos para testar\n",
        "# ------------------------------\n",
        "modelos = [\n",
        "     {\"nome\": \"FastConformer-Hybrid\", \"id\": \"nvidia/stt_pt_fastconformer_hybrid_large_pc\", \"tipo\": \"nemo\"},\n",
        "     {\"nome\": \"Citrinet-PT-Gamma-0.25\", \"id\": \"neongeckocom/stt_pt_citrinet_512_gamma_0_25\", \"tipo\": \"nemo\"},\n",
        "     {\"nome\": \"QuartzNet-PT-Ottema\", \"id\": \"ottema/stt_pt_quartznet15x5_ctc_small\", \"tipo\": \"nemo\"},\n",
        "     {\"nome\": \"QuartzNet-PT\", \"id\": \"dominguesm/stt_pt_quartznet15x5_ctc_small\", \"tipo\": \"nemo\"},\n",
        "     {\"nome\": \"Parakeet-TDT-0.6b-v3 (multilingual)\", \"id\": \"nvidia/parakeet-tdt-0.6b-v3\", \"tipo\": \"nemo\"},\n",
        "     {\"nome\": \"wav2vec2-PT-BR-Light\", \"id\": \"danielpedrozo/wav2vec2-portuguese-wpp-checkpoint-480\", \"tipo\": \"hf\"},\n",
        "]\n",
        "\n",
        "# ------------------------------\n",
        "# Execu√ß√£o e coleta de resultados\n",
        "# ------------------------------\n",
        "resultados = []\n",
        "\n",
        "for modelo in modelos:\n",
        "    try:\n",
        "        if modelo[\"tipo\"] == \"nemo\":\n",
        "            latencia, transcricao = avaliar_modelo_nemo(modelo[\"id\"], audio_teste)\n",
        "        elif modelo[\"tipo\"] == \"hf\":\n",
        "            latencia, transcricao = avaliar_modelo_hf(modelo[\"id\"], audio_teste)\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Tipo de modelo desconhecido: {modelo['nome']}\")\n",
        "            continue\n",
        "        metricas = calcular_metricas(modelo[\"nome\"], latencia, transcricao, referencia_texto)\n",
        "        resultados.append(metricas)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao avaliar modelo {modelo['nome']}: {e}\")\n",
        "\n",
        "# ------------------------------\n",
        "# Cria√ß√£o do DataFrame\n",
        "# ------------------------------\n",
        "df_resultados = pd.DataFrame(resultados)\n",
        "\n",
        "if \"Transcri√ß√£o\" in df_resultados.columns:\n",
        "    df_resultados[\"Transcri√ß√£o\"] = df_resultados[\"Transcri√ß√£o\"].apply(limpar_transcricao)\n",
        "\n",
        "# -------- ORDENA√á√ÉO --------\n",
        "colunas_ordem = [c for c in [\"WER aproximado\", \"Lat√™ncia (ms)\"] if c in df_resultados.columns]\n",
        "if colunas_ordem:\n",
        "    df_resultados = df_resultados.sort_values(\n",
        "        by=colunas_ordem,\n",
        "        ascending=[True] * len(colunas_ordem),\n",
        "        na_position=\"last\",\n",
        "        ignore_index=True\n",
        "    )\n",
        "\n",
        "# Adicionar coluna de ranking\n",
        "df_resultados.insert(0, \"Rank\", range(1, len(df_resultados) + 1))\n",
        "\n",
        "# -------- VISUALIZA√á√ÉO NO CONSOLE --------\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "pd.set_option(\"display.max_rows\", None)\n",
        "\n",
        "print(\"\\nüîπ Resultados ordenados (melhor WER e menor lat√™ncia):\")\n",
        "\n",
        "# Seleciona apenas colunas que realmente existem\n",
        "colunas_display = [c for c in [\"Rank\", \"Modelo\", \"WER aproximado\", \"Lat√™ncia (ms)\", \"Transcri√ß√£o\"] if c in df_resultados.columns]\n",
        "print(df_resultados[colunas_display])\n",
        "\n",
        "# -------- EXPORTA√á√ÉO --------\n",
        "saida_csv = \"resultados_asr.csv\"\n",
        "saida_txt = \"resultados_asr.txt\"\n",
        "\n",
        "df_resultados.to_csv(saida_csv, index=False, encoding=\"utf-8\")\n",
        "\n",
        "with open(saida_txt, \"w\", encoding=\"utf-8\") as f:\n",
        "    for _, row in df_resultados.iterrows():\n",
        "        f.write(f\"Modelo: {row.get('Modelo', 'N/A')}\\n\")\n",
        "        f.write(f\"WER aproximado: {row.get('WER aproximado', 'N/A')}\\n\")\n",
        "        f.write(f\"Lat√™ncia (ms): {row.get('Lat√™ncia (ms)', 'N/A')}\\n\")\n",
        "        f.write(f\"Transcri√ß√£o: {row.get('Transcri√ß√£o', '')}\\n\")\n",
        "        f.write(\"-\" * 60 + \"\\n\")\n",
        "\n",
        "print(f\"\\n‚úÖ Resultados salvos em: {saida_csv} e {saida_txt}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaMbcF8So6ON"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}